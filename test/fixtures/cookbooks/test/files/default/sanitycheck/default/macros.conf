[report_eventtypes_examples_by_clustering]
description = show 5 examples from each cluster, from most common cluster to least... 
definition  = cluster labelonly=t showcount=t| sort -cluster_count, cluster_label, _time | dedup 5 cluster_label | fields - time* date* source* host linecount*

[report_eventtypes_by_clustering]
description = show one example from each cluster, from most common cluster to least... 
definition  = cluster labelonly=t showcount=t| stats count, first(_raw) by cluster_label | sort - count 


[report_eventtypes_by_first_punctuation]
description = group events by most common first 5 punct characters
definition  = rex field=punct "(?P.{5})"| eval smallpunct= smallpunct + "*" | stats first(_raw) as example count by smallpunct | sort -count

[report_field_correlation]
description = discover patterns in extracted fields with the correlation table, which shows patterns of co-occurring fields. A 1.0 means two fields always co-occur. You can filter out fields to make this table more manageable.
definition   = fields - date* source* time* | correlate

[report_transaction_bursts]
description = look for pauses in your events, as real-physical events often happen in bursts
definition  = delta _time as timedelta | top timedelta 

[report_transaction_by_bursts]
description = group events into transactions, splitting when there is a pause of more than 2 seconds, and then filtering out all the transactions of size 1
definition  = transaction maxpause=2s | search eventcount>1

[report_event_major_slowdown]
description = find events with no events before or after them for 2 seconds, usually indicating a major restarting/rebooting.
definition  = transaction maxpause=2s | search eventcount=1

[report_anomalies_by_clustering]
description = find unexpected events by looking at those that do not cluster into large groups. 
definition  = cluster showcount=t | sort - cluster_count 

[report_anomalies_by_value(1)]
args = field
description = find unexpected events by finding values that are far from the standard deviation.
definition  = anomalousvalue $field$ action=filter pthresh=0.02

[report_transaction_cross-source_fields]
description = return the fields that occur in the most fields.  useful for joining data or transactions
definition = stats count(*) as * by source | stats dc(*) as *| transpose 1000 | rename "row 1" as sourcecount, column as field | search field!=*date* field!=source field!=eventtype field!=host field!=index field!=linecount field!=punct field!=sourcetype field!=splunk_server sourcecount>2 | sort - sourcecount 

[report_transaction_id_fields]
description = return the fields with the most unique values, possibly identifying unique IDs for transactions.
definition = stats dc(*) as * | transpose 1000 | rename "row 1" as count, column as field | sort - count

[report_transaction_non-numeric_id_fields(1)]
description = return non-numeric fields with the most unique values, possibly identifying unique IDs for transactions.
definition = $search$ | fields - [search $search$ | stats avg(*) as * | transpose 1000 | stats values(column) as search | format "" "" "" "" "" ""] | stats dc(*) as * | transpose 1000 | rename "row 1" as count, column as field | sort - count
args = search

[t_score(1)]
description = calculate some stats for quick and dirty normality tests
args = field
definition = stats count max($field$) as max min($field$) as min stdev($field$) as stdev avg($field$) as avg perc95($field$) as perc95 perc5($field$) as perc5 | eval max_t=(max-avg)* sqrt(count) / stdev | eval min_t = (min-avg)*sqrt(count) / stdev | eval perc95_t=(perc95-avg)*sqrt(count)/stdev | eval perc5_t=(perc5-avg)*sqrt(count)/stdev

[field_characteristics(1)]
description = tells whether the given field is numeric, and whether it has a high distinct count or not.
args = field
definition = stats count($field$) as count dc($field$) as dc sum(eval(isnum($field$))) as numeric_count | eval has_high_dc=if(dc>15, 1, 0) | eval is_numeric=if(numeric_count/count>0.7, 1, 0) | eval field="$field$" | fields field is_numeric has_high_dc

[suggest_reports(1)]
description = given a particular field it will examine fields in the given search results and suggest some simple but relevant reports on that field
args = field
definition =  inputlookup suggested_reports | appendcols [search index=_internal source=*metrics.log group=per_sourcetype_thruput | head 10000 | `field_characteristics($field$)` ] | streamstats first(has_high_dc) as has_high_dc first(is_numeric) as is_numeric | eval numeric_score=if(is_numeric=1,numeric, categorical) | eval dc_score=if(has_high_dc=1, high_dc, low_dc)  | eval total_score=numeric_score+dc_score | search total_score>2 numeric_score>0 dc_score>0 | sort - total_score | fields search total_score is_numeric has_high_dc numeric categorical high_dc low_dc numeric_score dc_score 

[get_fields(1)]
description = looks at the incoming results, summarizes the field names and the distinct counts and returns one row for each of those fields.
args = count
definition = |  head $count$ | stats dc(*) as * | transpose | rename column as field "row 1" as dc | search field!="date_*" field!=timestartpos field!=timeendpos


[get_distinct_count(1)]
description = tells whether the given field is numeric, and whether it has a high distinct count or not.
args = field
definition = stats dc($field$) as dc | eval has_high_dc=if(dc>15, 1, 0) | eval field="$field$" | fields field dc has_high_dc

[get_is_numeric(3)]
description = adds a column onto the results saying whether the given field is numeric.
args = field, depth, innerSearch
definition = appendcols [ `is_numeric(field=$field$, depth=$depth$, innerSearch="$innerSearch$")` | fields is_numeric]

#typical usage: 
#     `suggest_2d_reports(field=twikiuser, depth=10000, innerSearch="sourcetype=twiki")`
#     `suggest_2d_reports(field=attacker, depth=10000, innerSearch="sourcetype=cisco_ips_syslog")`
#     `suggest_2d_reports(field=eps, depth=10000, innerSearch="index=_internal source=*metrics.log")`
[suggest_2d_reports(3)]
description = Let me esplain. No there is too much.  Let me sum up. 
args = field, depth, innerSearch
definition =  $innerSearch$ $field$=* | head $depth$  | `get_distinct_count($field$)`  | `get_is_numeric(field=$field$, depth=$depth$, innerSearch="search $innerSearch$")` | rename field as field1 is_numeric as field1_is_numeric has_high_dc as field1_has_high_dc | eval foo=1 | join max=$depth$ foo [ search $innerSearch$ `get_fields($depth$)` | where dc>1 | eval field2_has_high_dc=if(dc>15, 1, 0) | rename field as field2 | fields - dc | eval foo=1] | fields - foo - dc | where field1!=field2 | fields field1 field2 * | eval foo=1  | join max=$depth$ foo [ | inputlookup suggested_2d_reports | where field2_low_dc + field2_high_dc > 0 | eval foo=1] | eval search=replace(search, "FIELD2", field2) | eval description=replace(description, "FIELD2", field2)  | append [  search $innerSearch$ | head $depth$ | `field_characteristics($field$)` | eval foo=1 | join max=$depth$ foo [ | inputlookup suggested_2d_reports | where field2_high_dc=0 and field2_low_dc=0 | eval foo=1 ] | rename field as field1 categorical as field1_categorical has_high_dc as field1_has_high_dc is_numeric as field1_is_numeric  ] | eval search=replace(search, "FIELD1", field1) | eval description=replace(description, "FIELD1", field1) | eval field1_numeric_score=if(field1_is_numeric=1,field1_numeric, field1_categorical) | eval field1_dc_score=if(field1_has_high_dc=1, field1_high_dc, field1_low_dc) | eval field2_dc_score=if(field2_has_high_dc=1, field2_high_dc, field2_low_dc) | eval total_score=field1_numeric_score+field1_dc_score + field2_dc_score | search total_score>2 field1_numeric_score>0 field1_dc_score>0 | sort - total_score | fields search description field2 total_score * 



#usage 
#`is_numeric(field=eps, depth=10000, innerSearch="index=_internal source=*metrics.log")`
#wtf
# this gets a bucketed chart of values by frequency. Even if the values look like numbers, if they're not representing some real scalar 
# quantity in the real world, then a given frequency for value=X will not be very predictive of a similar value being found at 
# X+1 or X-1.    Yes I tried normality tests, skew,kurtosis tests, t-tests.   Production data is so unbelievably noisy that these 
# all turned out to be worthless.   This approach seems to work for quite a lot of cases but I admit its a bit insane and it needs work
[is_numeric(3)]
description = returns a single field isNumeric, that tells whether the given field in the given search is actually a numeric quantity.
args = field, depth, innerSearch
definition = $innerSearch$ | search $field$=* | head $depth$ | chart count by $field$ bins=$depth$ | eval $field$=replace($field$, "-.+" ,"") | sort $field$ | delta p=1 count as nearDelta | delta p=17 count as farDelta1 | delta p=31 count as farDelta2 | delta p=47 count as farDelta3 | delta p=57 count as farDelta4 | search farDelta4=* | eval nearDelta=abs(nearDelta) | eval farDelta1=abs(farDelta1) | eval farDelta2=abs(farDelta2) | eval farDelta3=abs(farDelta3) | eval farDelta4=abs(farDelta4) | strcat farDelta1 "," farDelta2 "," farDelta3 "," farDelta4 "," far | makemv delim="," far | stats avg(nearDelta) as near avg(far) as far stdev(far) as farDev | eval numerosity=(far-near)/farDev | eval numerosity2=if(near*1.5<far,1,0) | eval is_numeric=if(numerosity>0 and numerosity2=1,1,0)


# SCRATCH PAD 0 
# definition = $innerSearch$ | search $field$=* | head $depth$ | stats count by $field$ | sort $field$ | delta p=1 count as nearDelta | delta p=7 count as farDelta1 | delta p=17 count as farDelta2 | delta p=31 count as farDelta3 | delta p=47 count as farDelta4 | search farDelta4=* | fields farDelta* nearDelta $field$ count | eval nearDelta=abs(nearDelta) | eval farDelta1=abs(farDelta1) | eval farDelta2=abs(farDelta2) | eval farDelta3=abs(farDelta3) | eval farDelta4=abs(farDelta4) | strcat farDelta1 "," farDelta2 "," farDelta3 "," farDelta4 "," far | makemv delim="," far | fillnull nearDelta | stats count stdev(*) as * | strcat farDelta1 "," farDelta2 "," farDelta3 "," farDelta4 "," far | makemv delim="," far | fillnull nearDelta |  stats sum(count) as count avg(nearDelta) as near values(far) as farValues avg(far) as far stdev(far) as farDev | eval numericNess=(far-near) / farDev | eval is_numeric=if(numericNess>1,1,0)


# SCRATCH PAD 1
# definition = $innerSearch$ | search $field$=* | head $depth$ | stats count by $field$ | sort $field$ | delta p=1 count as nearDelta | delta p=7 count as farDelta1 | delta p=17 count as farDelta2 | delta p=31 count as farDelta3 | delta p=47 count as farDelta4 | search farDelta4=* | fields farDelta* nearDelta | eval nearDelta=abs(nearDelta) | eval farDelta1=abs(farDelta1) | eval farDelta2=abs(farDelta2) | eval farDelta3=abs(farDelta3) | eval farDelta4=abs(farDelta4) | stats count stdev(*) as * | strcat farDelta1 "," farDelta2 "," farDelta3 "," farDelta4 "," far | makemv delim="," far | fillnull nearDelta |  stats sum(count) as count avg(nearDelta) as near values(far) as farValues avg(far) as far stdev(far) as farDev | eval is_numeric=if(far-(farDev*1.3) > near,1,0)

# SCRATCH PAD 2
#definition = $innerSearch$ $field$=* | head $depth$ | stats count by $field$ | sort $field$ | delta p=1 $field$ as nearDelta | delta p=7 $field$ as farDelta1 | delta p=17 $field$ as farDelta2 | delta p=31 $field$ as farDelta3 | delta p=47 $field$ as farDelta4 | search farDelta4=* | fields farDelta* nearDelta | eval nearDelta=abs(nearDelta) | eval farDelta1=abs(farDelta1) | eval farDelta2=abs(farDelta2) | eval farDelta3=abs(farDelta3) | eval farDelta4=abs(farDelta4) | stats count stdev(*) as * | strcat farDelta1 "," farDelta2 "," farDelta3 "," farDelta4 "," far | makemv delim="," far | fillnull nearDelta |  stats sum(count) as count avg(nearDelta) as near values(far) as farValues avg(far) as far stdev(far) as farDev | eval isNumeric=if(far-(farDev*1.3) > near,1,0)

# SCRATCH PAD 3
# definition = $innerSearch$ $field$=* | head $depth$ | chart count over $field$ | bin $field$ bins=10000 | delta p=1 count as nearDelta1 | delta p=2 count as nearDelta2 | delta p=3 count as nearDelta3 | delta p=4 count as nearDelta4 | delta p=10 count as farDelta1 | delta p=20 count as farDelta2 | delta p=30 count as farDelta3 | delta p=40 count as farDelta4 | fields farDelta* nearDelta* | stats count stdev(*) as * | strcat farDelta1 "," farDelta2 "," farDelta3 "," farDelta4 "," far | strcat nearDelta1 "," nearDelta2 "," nearDelta3 "," nearDelta4 "," near |  makemv delim="," far | makemv delim="," near | fields near far | stats sum(count) as count avg(near) as near stdev(near) as nearDev avg(far) as far stdev(far) as farDev | eval isNumeric=if(far-farDev > near,1,0)


#cases that should be identified as numeric
# `is_numeric(field=kbps, depth=10000, innerSearch="index=_internal source=*metrics.log")`
# `is_numeric(field=eps, depth=10000, innerSearch="index=_internal source=*metrics.log")`
# `is_numeric(field=kb, depth=10000, innerSearch="index=_internal source=*metrics.log")`
# `is_numeric(field=pri, depth=5000, innerSearch="index=sandbox sourcetype=sendmail_syslog")`
# `is_numeric(field=bytes, depth=10000, innerSearch="host=ccb index=sandbox")`
# `is_numeric(field=exec_time, depth=10000, innerSearch="index=_audit")`
# `is_numeric(field=result_count, depth=10000, innerSearch="index=_internal sourcetype=scheduler")`
# `is_numeric(field=ntries, depth=10000, innerSearch="index=sandbox sourcetype=sendmail_syslog")`
# `is_numeric(field=size, depth=10000, innerSearch="index=sandbox sourcetype=sendmail_syslog")`

#cases that should be identified as categorical
# `is_numeric(field=pid, depth=10000, innerSearch="index=sandbox sourcetype=sendmail_syslog")`
# `is_numeric(field=foo, depth=10000, innerSearch="index=_internal | head 10000 | eval foo=round(random()/100000)")`

#cases where it returns negative cause dc is not high enough
# `is_numeric(field=genre, depth=10000, innerSearch="index=sandbox host=ccb")`



#cases where its NOT technically numeric but it thinks it is, and the data is actually kind of interesting as numeric data. 
# `is_numeric(field=id, depth=10000, innerSearch="index=sandbox host=ccb")`
  
# less than idea cases.
# `is_numeric(field=page, depth=10000, innerSearch="index=sandbox host=ccb page=*")`

#----------------------------------------------------------------------------------------------------------------------------------------------------------------------------



#typical usage: 
#     `suggest_2d_reports(field=twikiuser, maxmatches=10000, innerSearch="search sourcetype=twiki")`
[fast_suggest_2d_reports(3)]
description = Let me esplain. No there is too much.  Let me sum up. 
args = sid, field, maxmatches
definition = loadjob $sid$ | head $maxmatches$ | `get_distinct_count($field$)` | `fast_get_is_numeric(field=$field$, maxmatches=$maxmatches$, sid=$sid$)` | rename field as field1 is_numeric as field1_is_numeric has_high_dc as field1_has_high_dc | eval foo=1 | join max=$maxmatches$ foo [ loadjob $sid$ `get_fields($maxmatches$)` | where dc>1 | eval field2_has_high_dc=if(dc>15, 1, 0) | rename field as field2 | fields - dc | eval foo=1] | fields - foo - dc | where field1!=field2 | fields field1 field2 * | eval foo=1  | join max=$maxmatches$ foo [  | inputlookup suggested_2d_reports | where field2_low_dc + field2_high_dc > 0 | eval foo=1] | eval search=replace(search, "FIELD2", field2) | eval description=replace(description, "FIELD2", field2)  | append [ loadjob $sid$ | head $maxmatches$ | `field_characteristics($field$)` | eval foo=1 | join max=$maxmatches$ foo [ | inputlookup suggested_2d_reports | where field2_high_dc=0 and field2_low_dc=0 | eval foo=1 ] | rename field as field1 categorical as field1_categorical has_high_dc as field1_has_high_dc is_numeric as field1_is_numeric ] | eval search=replace(search, "FIELD1", field1) | eval description=replace(description, "FIELD1", field1) | eval field1_numeric_score=if(field1_is_numeric=1,field1_numeric, field1_categorical) | eval field1_dc_score=if(field1_has_high_dc=1, field1_high_dc, field1_low_dc) | eval field2_dc_score=if(field2_has_high_dc=1, field2_high_dc, field2_low_dc) | eval total_score=field1_numeric_score+field1_dc_score + field2_dc_score | search total_score>2 field1_numeric_score>0 field1_dc_score>0 | sort - total_score | fields search description field2 total_score * 

[fast_get_is_numeric(3)]
description = returns a single field isNumeric, that tells whether the given field in the given search is actually a numeric quantity.
args = field, maxmatches, sid
definition = appendcols [ loadjob $sid$ | search $field$=* | head $maxmatches$ | chart count by $field$ bins=$maxmatches$ | eval $field$=replace($field$, "-.+" ,"") | sort $field$ | delta p=1 count as nearDelta | delta p=17 count as farDelta1 | delta p=31 count as farDelta2 | delta p=47 count as farDelta3 | delta p=57 count as farDelta4 | search farDelta4=* | eval nearDelta=abs(nearDelta) | eval farDelta1=abs(farDelta1) | eval farDelta2=abs(farDelta2) | eval farDelta3=abs(farDelta3) | eval farDelta4=abs(farDelta4) | strcat farDelta1 "," farDelta2 "," farDelta3 "," farDelta4 "," far | makemv delim="," far | stats avg(nearDelta) as near avg(far) as far stdev(far) as farDev | eval numerosity=(far-near)/farDev | eval numerosity2=if(near*1.5<far,1,0) | eval is_numeric=if(numerosity>0 and numerosity2=1,1,0) | fields is_numeric]
